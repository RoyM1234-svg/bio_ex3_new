{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-k0q29Z3ukKI"
   },
   "outputs": [],
   "source": [
    "# # delete this cell if working on Pycharm\n",
    "# !pip install Bio\n",
    "# !pip install import-ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "tCeXnsvlLtE-"
   },
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# so we can import utils notebook (delete if working on Pycharm), you might need to change it to your working directory path\n",
    "# %cd \"/content/drive/MyDrive/Ex4Files/\" \n",
    "import import_ipynb\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6y4fRqWLLwhR"
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "#                                                                             #\n",
    "#              Parameters you can change, but don't have to                   #\n",
    "#                                                                             #\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "# number of ResNet blocks for the first ResNet and the kernel size.\n",
    "RESNET_1_BLOCKS = 3 \n",
    "RESNET_1_KERNEL_SIZE = 15\n",
    "RESNET_1_KERNEL_NUM = 64\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "#                                                                             #\n",
    "#                        Parameters you need to choose                        #\n",
    "#                                                                             #\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "# number of ResNet blocks for the second ResNet, dilation list to repeat and the kernel size.\n",
    "\n",
    "RESNET_2_BLOCKS = 1 \n",
    "RESNET_2_KERNEL_SIZE = 1  # good start may be 3/5\n",
    "RESNET_2_KERNEL_NUM = 1\n",
    "DILATION = [1]\n",
    "\n",
    "# percentage of dropout for the dropout layer\n",
    "DROPOUT = 0.0 # good start may be 0.1-0.5\n",
    "\n",
    "# number of epochs, Learning rate and Batch size\n",
    "EPOCHS = 1\n",
    "LR = 0.001 # good start may be 0.0001/0.001/0.01\n",
    "BATCH = 1 # good start may be 32/64/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z7wc4YJMo5V-"
   },
   "outputs": [],
   "source": [
    "def resnet_1(input_layer):\n",
    "    \"\"\"\n",
    "    ResNet layer - input -> BatchNormalization -> Conv1D -> Relu -> BatchNormalization -> Conv1D -> Relu -> Add\n",
    "    :param input_layer: input layer for the ResNet\n",
    "    :return: last layer of the ResNet\n",
    "    \"\"\"\n",
    "    for i in range(RESNET_1_BLOCKS):\n",
    "        batch_norm_layer = layers.BatchNormalization()(input_layer)\n",
    "        conv1d_layer = layers.Conv1D(RESNET_1_KERNEL_NUM, RESNET_1_KERNEL_SIZE, activation='relu', padding='same')(batch_norm_layer)\n",
    "        batch_norm_layer = layers.BatchNormalization()(conv1d_layer)\n",
    "        input_layer = layers.Conv1D(RESNET_1_KERNEL_NUM, RESNET_1_KERNEL_SIZE, activation='relu', padding='same')(batch_norm_layer) + input_layer\n",
    "    return input_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NXj05_d7o5io"
   },
   "outputs": [],
   "source": [
    "def resnet_2(input_layer):  # TODO: implement this!\n",
    "    \"\"\"\n",
    "    Dilated ResNet layer - input -> BatchNormalization -> dilated Conv1D -> Relu -> BatchNormalization -> dilated Conv1D -> Relu -> Add\n",
    "    :param input_layer: input layer for the ResNet\n",
    "    :return: last layer of the ResNet\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y_CN7eEopE3A"
   },
   "outputs": [],
   "source": [
    "def build_network():\n",
    "    \"\"\"\n",
    "    builds the neural network architecture as shown in the exercise.\n",
    "    :return: a Keras Model\n",
    "    \"\"\"\n",
    "    # input, shape (NB_MAX_LENGTH,FEATURE_NUM)\n",
    "    input_layer = tf.keras.Input(shape=(utils.NB_MAX_LENGTH, utils.FEATURE_NUM))\n",
    "\n",
    "    # Conv1D -> shape = (NB_MAX_LENGTH, RESNET_1_KERNEL_NUM)\n",
    "    conv1d_layer = layers.Conv1D(RESNET_1_KERNEL_NUM, RESNET_1_KERNEL_SIZE, padding='same')(input_layer)\n",
    "\n",
    "    # first ResNet -> shape = (NB_MAX_LENGTH, RESNET_1_KERNEL_NUM)\n",
    "    resnet_layer = resnet_1(conv1d_layer)\n",
    "\n",
    "    # Conv1D -> shape = (NB_MAX_LENGTH, RESNET_2_KERNEL_NUM)\n",
    "    conv1d_layer = layers.Conv1D(RESNET_2_KERNEL_NUM, RESNET_2_KERNEL_SIZE, padding=\"same\")(resnet_layer)\n",
    "\n",
    "    # second ResNet -> shape = (NB_MAX_LENGTH, RESNET_2_KERNEL_NUM)\n",
    "    resnet_layer = resnet_2(conv1d_layer)\n",
    "\n",
    "\n",
    "    # TODO: fill the missing layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8itDQ59HpFlL"
   },
   "outputs": [],
   "source": [
    "def plot_val_train_loss(history):\n",
    "    \"\"\"\n",
    "    plots the train and validation loss of the model at each epoch, saves it in 'model_loss_history.png'\n",
    "    :param history: history object (output of fit function)\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    ig, axes = plt.subplots(1, 1, figsize=(15,3))\n",
    "    axes.plot(history.history['loss'], label='Training loss')\n",
    "    axes.plot(history.history['val_loss'], label='Validation loss')\n",
    "    axes.legend()\n",
    "    axes.set_title(\"Train and Val MSE loss\")\n",
    "\n",
    "    plt.savefig(\"/content/drive/MyDrive/Ex4Files/model_loss_history\")  # TODO: you can change the path here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TQLxqy33pJk2"
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    model = build_network()\n",
    "\n",
    "    # you can load here your input and output data\n",
    "\n",
    "    # X = numpy array of shape (1974,NB_MAX_LENGTH,FEATURE_NUM) of all the data input.\n",
    "    # Y = numpy array of shape (1974,NB_MAX_LENGTH,OUTPUT_SIZE) of all the data labels.\n",
    "\n",
    "    # split into validation and test sets as you like\n",
    "\n",
    "    # b)\n",
    "    #  compile model using Adam optimizer (with learning rate of your choice) and MSE loss.\n",
    "\n",
    "    # c)\n",
    "    # fit model (use EPOCH for epoch parameter and BATCH for batch_size parameter)\n",
    "\n",
    "    # d)\n",
    "    # save model\n",
    "\n",
    "\n",
    "    # part 3 predict\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNIhjSEWmJb0aKKFERG4uLc",
   "collapsed_sections": [],
   "mount_file_id": "1bMh8NMf9dmXjwMDYp3vDQ53Q5hzJ-8j8",
   "name": "net.ipynb",
   "provenance": [
    {
     "file_id": "1Z4rejvEyNAlkKdlatOrHZY_Uaa7hyUPz",
     "timestamp": 1618652037590
    }
   ]
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
